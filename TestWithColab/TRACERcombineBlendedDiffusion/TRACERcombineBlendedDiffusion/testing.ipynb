{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMrlq17eAYVyhNiHKL7CFgO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMeKOTKJMSaA","executionInfo":{"status":"ok","timestamp":1696063102853,"user_tz":-420,"elapsed":2647,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"86926b48-6943-4b41-e023-0584d7646f43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Replace-Anything'...\n","remote: Enumerating objects: 42, done.\u001b[K\n","remote: Counting objects: 100% (42/42), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 42 (delta 13), reused 20 (delta 2), pack-reused 0\u001b[K\n","Receiving objects: 100% (42/42), 14.10 MiB | 8.32 MiB/s, done.\n","Resolving deltas: 100% (13/13), done.\n"]}],"source":["!git clone https://github.com/yuqwu/Replace-Anything.git"]},{"cell_type":"code","source":["cd Replace-Anything"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywsVVeGwMa1O","executionInfo":{"status":"ok","timestamp":1696063102854,"user_tz":-420,"elapsed":7,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"0c622af7-0245-451c-f85b-804ed91dab48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Replace-Anything\n"]}]},{"cell_type":"code","source":["!./download_model.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kG41MduRMzGH","executionInfo":{"status":"ok","timestamp":1696063118654,"user_tz":-420,"elapsed":15805,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"13e2debd-580c-42dc-9608-c9c136ce5e54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-30 08:38:22--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 52.84.251.15, 52.84.251.106, 52.84.251.114, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|52.84.251.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2564550879 (2.4G) [binary/octet-stream]\n","Saving to: ‘./models/sam_vit_h_4b8939.pth’\n","\n","sam_vit_h_4b8939.pt 100%[===================>]   2.39G   207MB/s    in 16s     \n","\n","2023-09-30 08:38:37 (157 MB/s) - ‘./models/sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n","\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeSNlAIHNRZy","executionInfo":{"status":"ok","timestamp":1696063155733,"user_tz":-420,"elapsed":37082,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"41b01635-f42c-4fb9-c885-835f1754c867"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/segment-anything.git (from -r requirements.txt (line 13))\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-_obbtwiy\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-_obbtwiy\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting bentoml (from -r requirements.txt (line 1))\n","  Downloading bentoml-1.1.6-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting diffusers==0.11.1 (from -r requirements.txt (line 2))\n","  Downloading diffusers-0.11.1-py3-none-any.whl (524 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.9/524.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.8.0.76)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Collecting gradio (from -r requirements.txt (line 5))\n","  Downloading gradio-3.45.2-py3-none-any.whl (20.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.15.2+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.0.2+cu118)\n","Collecting transformers (from -r requirements.txt (line 9))\n","  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.2)\n","Collecting ftfy (from -r requirements.txt (line 11))\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate (from -r requirements.txt (line 12))\n","  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.11.1->-r requirements.txt (line 2)) (6.8.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.11.1->-r requirements.txt (line 2)) (3.12.2)\n","Collecting huggingface-hub>=0.10.0 (from diffusers==0.11.1->-r requirements.txt (line 2))\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.11.1->-r requirements.txt (line 2)) (1.23.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.11.1->-r requirements.txt (line 2)) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.11.1->-r requirements.txt (line 2)) (2.31.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.11.1->-r requirements.txt (line 2)) (9.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (3.8.5)\n","Requirement already satisfied: attrs>=21.1.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (23.1.0)\n","Collecting cattrs>=22.1.0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading cattrs-23.1.2-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting circus!=0.17.2,>=0.17.0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading circus-0.18.0-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting click-option-group (from bentoml->-r requirements.txt (line 1))\n","  Downloading click_option_group-0.5.6-py3-none-any.whl (12 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (8.1.7)\n","Requirement already satisfied: cloudpickle>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (2.2.1)\n","Collecting deepmerge (from bentoml->-r requirements.txt (line 1))\n","  Downloading deepmerge-1.1.0-py3-none-any.whl (8.5 kB)\n","Collecting fs (from bentoml->-r requirements.txt (line 1))\n","  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting inflection (from bentoml->-r requirements.txt (line 1))\n","  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: jinja2>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (3.1.2)\n","Collecting opentelemetry-api==1.18.0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_api-1.18.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation-aiohttp-client==0.39b0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_instrumentation_aiohttp_client-0.39b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.39b0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_instrumentation_asgi-0.39b0-py3-none-any.whl (13 kB)\n","Collecting opentelemetry-instrumentation==0.39b0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_instrumentation-0.39b0-py3-none-any.whl (24 kB)\n","Collecting opentelemetry-sdk==1.18.0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_sdk-1.18.0-py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-semantic-conventions==0.39b0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_semantic_conventions-0.39b0-py3-none-any.whl (26 kB)\n","Collecting opentelemetry-util-http==0.39b0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading opentelemetry_util_http-0.39b0-py3-none-any.whl (6.7 kB)\n","Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (23.1)\n","Collecting pathspec (from bentoml->-r requirements.txt (line 1))\n","  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n","Collecting pip-requirements-parser>=31.2.0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading pip_requirements_parser-32.0.1-py3-none-any.whl (35 kB)\n","Requirement already satisfied: pip-tools>=6.6.2 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (6.13.0)\n","Requirement already satisfied: prometheus-client>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (0.17.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (5.9.5)\n","Collecting pynvml<12 (from bentoml->-r requirements.txt (line 1))\n","  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (2.8.2)\n","Collecting python-json-logger (from bentoml->-r requirements.txt (line 1))\n","  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n","Collecting python-multipart (from bentoml->-r requirements.txt (line 1))\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (6.0.1)\n","Requirement already satisfied: rich>=11.2.0 in /usr/local/lib/python3.10/dist-packages (from bentoml->-r requirements.txt (line 1)) (13.5.2)\n","Collecting schema (from bentoml->-r requirements.txt (line 1))\n","  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n","Collecting simple-di>=0.1.4 (from bentoml->-r requirements.txt (line 1))\n","  Downloading simple_di-0.1.5-py3-none-any.whl (9.8 kB)\n","Collecting starlette>=0.13.5 (from bentoml->-r requirements.txt (line 1))\n","  Downloading starlette-0.31.1-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn (from bentoml->-r requirements.txt (line 1))\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.15.0 (from bentoml->-r requirements.txt (line 1))\n","  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting deprecated>=1.2.6 (from opentelemetry-api==1.18.0->bentoml->-r requirements.txt (line 1))\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting importlib-metadata (from diffusers==0.11.1->-r requirements.txt (line 2))\n","  Downloading importlib_metadata-6.0.1-py3-none-any.whl (21 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api==1.18.0->bentoml->-r requirements.txt (line 1)) (67.7.2)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.39b0->bentoml->-r requirements.txt (line 1)) (1.15.0)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.39b0->bentoml->-r requirements.txt (line 1))\n","  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk==1.18.0->bentoml->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.1)\n","Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 5))\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (4.2.2)\n","Collecting fastapi (from gradio->-r requirements.txt (line 5))\n","  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 5))\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.5.3 (from gradio->-r requirements.txt (line 5))\n","  Downloading gradio_client-0.5.3-py3-none-any.whl (298 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 5))\n","  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m360.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (6.0.1)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (2.1.3)\n","Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 5))\n","  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (1.5.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 5)) (1.10.12)\n","Collecting pydub (from gradio->-r requirements.txt (line 5))\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 5))\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting websockets<12.0,>=10.0 (from gradio->-r requirements.txt (line 5))\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.3->gradio->-r requirements.txt (line 5)) (2023.6.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 6)) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 6)) (16.0.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 9))\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 9))\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 9)) (4.66.1)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 11)) (0.2.6)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 5)) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 5)) (4.19.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 5)) (0.12.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.1.0->bentoml->-r requirements.txt (line 1)) (1.1.3)\n","Requirement already satisfied: pyzmq>=17.0 in /usr/local/lib/python3.10/dist-packages (from circus!=0.17.2,>=0.17.0->bentoml->-r requirements.txt (line 1)) (23.2.1)\n","Requirement already satisfied: tornado>=5.0.2 in /usr/local/lib/python3.10/dist-packages (from circus!=0.17.2,>=0.17.0->bentoml->-r requirements.txt (line 1)) (6.3.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.11.1->-r requirements.txt (line 2)) (3.16.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 5)) (2023.3.post1)\n","Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.6.2->bentoml->-r requirements.txt (line 1)) (1.0.3)\n","Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.6.2->bentoml->-r requirements.txt (line 1)) (23.1.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.6.2->bentoml->-r requirements.txt (line 1)) (0.41.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->bentoml->-r requirements.txt (line 1)) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.11.1->-r requirements.txt (line 2)) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.11.1->-r requirements.txt (line 2)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.11.1->-r requirements.txt (line 2)) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.11.1->-r requirements.txt (line 2)) (2023.7.22)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->bentoml->-r requirements.txt (line 1)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->bentoml->-r requirements.txt (line 1)) (2.16.1)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.13.5->bentoml->-r requirements.txt (line 1)) (3.7.1)\n","Collecting h11>=0.8 (from uvicorn->bentoml->-r requirements.txt (line 1))\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->bentoml->-r requirements.txt (line 1)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->bentoml->-r requirements.txt (line 1)) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->bentoml->-r requirements.txt (line 1)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->bentoml->-r requirements.txt (line 1)) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->bentoml->-r requirements.txt (line 1)) (1.3.1)\n","Collecting starlette>=0.13.5 (from bentoml->-r requirements.txt (line 1))\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs->bentoml->-r requirements.txt (line 1)) (1.4.4)\n","Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->-r requirements.txt (line 5))\n","  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 5)) (1.3.0)\n","Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->bentoml->-r requirements.txt (line 1)) (21.6.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 5)) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 5)) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 5)) (0.10.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->bentoml->-r requirements.txt (line 1)) (0.1.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.6.2->bentoml->-r requirements.txt (line 1)) (1.0.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.6.2->bentoml->-r requirements.txt (line 1)) (2.0.1)\n","Building wheels for collected packages: segment-anything, ffmpy\n","  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36586 sha256=a6a06a852e5eec76732a22d8e5d88fbeb7af4d5d2c8fd064b7a08a2b1487ec74\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bn325o_t/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=157879fcfd96cc96662850f44c6d10049589ba3d0fef1eeb0b7d4def49e791a2\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built segment-anything ffmpy\n","Installing collected packages: tokenizers, segment-anything, safetensors, pydub, ffmpy, deepmerge, websockets, simple-di, semantic-version, schema, python-multipart, python-json-logger, pynvml, pip-requirements-parser, pathspec, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, inflection, importlib-metadata, h11, ftfy, fs, deprecated, click-option-group, circus, cattrs, asgiref, aiofiles, watchfiles, uvicorn, starlette, opentelemetry-api, huggingface-hub, httpcore, transformers, opentelemetry-sdk, opentelemetry-instrumentation, httpx, fastapi, diffusers, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-aiohttp-client, gradio-client, gradio, bentoml, accelerate\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 6.8.0\n","    Uninstalling importlib-metadata-6.8.0:\n","      Successfully uninstalled importlib-metadata-6.8.0\n","Successfully installed accelerate-0.23.0 aiofiles-23.2.1 asgiref-3.7.2 bentoml-1.1.6 cattrs-23.1.2 circus-0.18.0 click-option-group-0.5.6 deepmerge-1.1.0 deprecated-1.2.14 diffusers-0.11.1 fastapi-0.103.2 ffmpy-0.3.1 fs-2.4.16 ftfy-6.1.1 gradio-3.45.2 gradio-client-0.5.3 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 importlib-metadata-6.0.1 inflection-0.5.1 opentelemetry-api-1.18.0 opentelemetry-instrumentation-0.39b0 opentelemetry-instrumentation-aiohttp-client-0.39b0 opentelemetry-instrumentation-asgi-0.39b0 opentelemetry-sdk-1.18.0 opentelemetry-semantic-conventions-0.39b0 opentelemetry-util-http-0.39b0 orjson-3.9.7 pathspec-0.11.2 pip-requirements-parser-32.0.1 pydub-0.25.1 pynvml-11.5.0 python-json-logger-2.0.7 python-multipart-0.0.6 safetensors-0.3.3 schema-0.7.5 segment-anything-1.0 semantic-version-2.10.0 simple-di-0.1.5 starlette-0.27.0 tokenizers-0.13.3 transformers-4.33.3 uvicorn-0.23.2 watchfiles-0.20.0 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["!bentoml serve"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keIViiD7OLBC","executionInfo":{"status":"ok","timestamp":1696063459026,"user_tz":-420,"elapsed":303296,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"72345892-ad56-489c-d915-7658e41bd706"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-09-30 08:39:28.782721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-09-30T08:39:30+0000 [INFO] [cli] Environ for worker 0: set CUDA_VISIBLE_DEVICES to 0\n","2023-09-30T08:39:30+0000 [INFO] [cli] Environ for worker 0: set CUDA_VISIBLE_DEVICES to 0\n","2023-09-30T08:39:30+0000 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \".\" can be accessed at http://localhost:3000/metrics.\n","2023-09-30T08:39:31+0000 [INFO] [cli] Starting production HTTP BentoServer from \".\" listening on http://0.0.0.0:3000 (Press CTRL+C to quit)\n","2023-09-30 08:39:55.952535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-09-30 08:39:57.028166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-09-30 08:39:57.417735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-09-30 08:39:57.558005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Downloading (…)ain/model_index.json: 100% 548/548 [00:00<00:00, 2.33MB/s]\n","vae/diffusion_pytorch_model.safetensors not found\n","Fetching 24 files:   0% 0/24 [00:00<?, ?it/s]\n","Downloading (…)e8e7b49d/config.json: 100% 748/748 [00:00<00:00, 2.78MB/s]\n","Fetching 24 files:   4% 1/24 [00:01<00:31,  1.39s/it]\n","Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 1.53MB/s]\n","Fetching 24 files:   8% 2/24 [00:01<00:13,  1.58it/s]\n","Downloading (…)_encoder/config.json: 100% 617/617 [00:00<00:00, 2.43MB/s]\n","\n","Downloading (…)cheduler_config.json: 100% 313/313 [00:00<00:00, 1.35MB/s]\n","\n","Downloading (…)_checker/config.json: 100% 4.78k/4.78k [00:00<00:00, 15.3MB/s]\n","Fetching 24 files:  17% 4/24 [00:01<00:06,  3.20it/s]\n","Downloading pytorch_model.bin:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\n","Downloading pytorch_model.bin:   1% 10.5M/1.22G [00:00<00:15, 77.6MB/s]\u001b[A\n","\n","Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 27.8MB/s]\n","\n","Downloading pytorch_model.bin:   2% 21.0M/1.22G [00:00<00:17, 68.9MB/s]\u001b[A\n","Downloading pytorch_model.bin:   3% 31.5M/1.22G [00:00<00:14, 80.0MB/s]\u001b[A\n","\n","Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 1.67MB/s]\n","\n","\n","Downloading model.fp16.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:   0% 0.00/492M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   4% 52.4M/1.22G [00:00<00:12, 91.3MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:   4% 10.5M/246M [00:00<00:03, 68.4MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:   2% 10.5M/492M [00:00<00:06, 75.5MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   5% 62.9M/1.22G [00:00<00:12, 92.9MB/s]\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   4% 10.5M/246M [00:00<00:03, 64.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:   9% 21.0M/246M [00:00<00:03, 69.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)okenizer_config.json: 100% 806/806 [00:00<00:00, 1.33MB/s]\n","\n","\n","\n","Downloading pytorch_model.bin:   4% 21.0M/492M [00:00<00:06, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   6% 73.4M/1.22G [00:00<00:17, 67.0MB/s]\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   9% 21.0M/246M [00:00<00:04, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  13% 31.5M/246M [00:00<00:03, 55.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:   6% 31.5M/492M [00:00<00:08, 55.7MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   7% 83.9M/1.22G [00:01<00:16, 69.5MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:  17% 41.9M/246M [00:00<00:03, 57.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  13% 31.5M/246M [00:00<00:04, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:   2% 10.5M/608M [00:00<00:12, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   2% 10.5M/608M [00:00<00:14, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:   9% 41.9M/492M [00:00<00:09, 50.0MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   8% 94.4M/1.22G [00:01<00:19, 58.6MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 2.07MB/s]\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  17% 41.9M/246M [00:00<00:04, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  21% 52.4M/246M [00:01<00:04, 41.9MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  11% 52.4M/492M [00:01<00:09, 46.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:   3% 21.0M/608M [00:00<00:17, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   3% 21.0M/608M [00:00<00:16, 36.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   9% 105M/1.22G [00:01<00:22, 48.5MB/s] \u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  21% 52.4M/246M [00:01<00:04, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   5% 31.5M/608M [00:00<00:14, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:   5% 31.5M/608M [00:00<00:16, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  26% 62.9M/246M [00:01<00:04, 40.2MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  13% 62.9M/492M [00:01<00:10, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:   9% 115M/1.22G [00:01<00:23, 46.7MB/s]\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  26% 62.9M/246M [00:01<00:04, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:   7% 41.9M/608M [00:01<00:14, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  30% 73.4M/246M [00:01<00:04, 40.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   7% 41.9M/608M [00:01<00:14, 37.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  15% 73.4M/492M [00:01<00:10, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:   9% 52.4M/608M [00:01<00:12, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  10% 126M/1.22G [00:02<00:26, 41.0MB/s]\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  30% 73.4M/246M [00:01<00:04, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  34% 83.9M/246M [00:01<00:03, 43.2MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  17% 83.9M/492M [00:01<00:09, 43.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:   9% 52.4M/608M [00:01<00:14, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  11% 136M/1.22G [00:02<00:25, 42.7MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:  38% 94.4M/246M [00:02<00:03, 46.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   0% 10.5M/3.44G [00:00<01:32, 37.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  34% 83.9M/246M [00:01<00:03, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  10% 62.9M/608M [00:01<00:13, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  10% 62.9M/608M [00:01<00:13, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  12% 147M/1.22G [00:02<00:22, 46.8MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  19% 94.4M/492M [00:02<00:09, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  43% 105M/246M [00:02<00:03, 43.7MB/s] \u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  12% 73.4M/608M [00:01<00:12, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  38% 94.4M/246M [00:02<00:03, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   1% 21.0M/3.44G [00:00<01:41, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   1% 10.5M/1.72G [00:00<00:52, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  12% 73.4M/608M [00:01<00:14, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  13% 157M/1.22G [00:03<00:25, 41.0MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  21% 105M/492M [00:02<00:10, 36.3MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  14% 83.9M/608M [00:02<00:11, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  47% 115M/246M [00:02<00:03, 40.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  43% 105M/246M [00:02<00:03, 38.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   1% 31.5M/3.44G [00:00<01:42, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   1% 21.0M/1.72G [00:00<01:01, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  14% 168M/1.22G [00:03<00:28, 36.7MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  23% 115M/492M [00:02<00:10, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  14% 83.9M/608M [00:02<00:15, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  16% 94.4M/608M [00:02<00:13, 38.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  51% 126M/246M [00:02<00:03, 39.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  47% 115M/246M [00:02<00:03, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   1% 41.9M/3.44G [00:01<01:37, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  26% 126M/492M [00:03<00:10, 36.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  55% 136M/246M [00:03<00:02, 36.9MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  15% 178M/1.22G [00:03<00:30, 33.9MB/s]\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  51% 126M/246M [00:03<00:03, 33.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   2% 52.4M/3.44G [00:01<01:41, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   2% 31.5M/1.72G [00:01<01:10, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  17% 105M/608M [00:02<00:16, 31.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  16% 94.4M/608M [00:02<00:18, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  28% 136M/492M [00:03<00:09, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  16% 189M/1.22G [00:03<00:28, 35.6MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:  60% 147M/246M [00:03<00:02, 37.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  55% 136M/246M [00:03<00:03, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   2% 62.9M/3.44G [00:01<01:33, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   2% 41.9M/1.72G [00:01<01:08, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  17% 105M/608M [00:03<00:18, 27.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  30% 147M/492M [00:03<00:10, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  64% 157M/246M [00:03<00:02, 32.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  19% 115M/608M [00:03<00:19, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  16% 199M/1.22G [00:04<00:34, 29.8MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   2% 73.4M/3.44G [00:02<01:47, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  60% 147M/246M [00:03<00:03, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   3% 52.4M/1.72G [00:02<01:07, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  32% 157M/492M [00:04<00:11, 30.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  19% 115M/608M [00:03<00:18, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   2% 83.9M/3.44G [00:02<01:45, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  68% 168M/246M [00:04<00:02, 29.2MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  17% 210M/1.22G [00:04<00:36, 27.5MB/s]\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  21% 126M/608M [00:03<00:20, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  64% 157M/246M [00:04<00:03, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   4% 62.9M/1.72G [00:02<01:05, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  21% 126M/608M [00:04<00:18, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  34% 168M/492M [00:04<00:11, 28.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   3% 94.4M/3.44G [00:02<01:49, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  18% 220M/1.22G [00:05<00:34, 28.9MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:  72% 178M/246M [00:04<00:02, 27.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  68% 168M/246M [00:04<00:02, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   4% 73.4M/1.72G [00:02<01:02, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  22% 136M/608M [00:04<00:20, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  22% 136M/608M [00:04<00:17, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  36% 178M/492M [00:05<00:11, 27.0MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  19% 231M/1.22G [00:05<00:33, 29.3MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:  77% 189M/246M [00:05<00:01, 28.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   3% 105M/3.44G [00:03<01:57, 28.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  72% 178M/246M [00:05<00:02, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   5% 83.9M/1.72G [00:03<00:56, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  24% 147M/608M [00:04<00:18, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  24% 147M/608M [00:04<00:17, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  20% 241M/1.22G [00:05<00:33, 29.1MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  38% 189M/492M [00:05<00:11, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   3% 115M/3.44G [00:03<02:02, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  81% 199M/246M [00:05<00:01, 26.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   5% 94.4M/1.72G [00:03<00:58, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  77% 189M/246M [00:05<00:02, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  26% 157M/608M [00:05<00:18, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  21% 252M/1.22G [00:06<00:33, 29.0MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  26% 157M/608M [00:05<00:17, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   4% 126M/3.44G [00:04<01:58, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  85% 210M/246M [00:05<00:01, 26.7MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  40% 199M/492M [00:05<00:11, 25.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   6% 105M/1.72G [00:03<01:00, 26.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  81% 199M/246M [00:05<00:01, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  28% 168M/608M [00:05<00:17, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   4% 136M/3.44G [00:04<01:53, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  28% 168M/608M [00:05<00:16, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  22% 262M/1.22G [00:06<00:35, 27.2MB/s]\u001b[A\n","\n","Downloading model.fp16.safetensors:  89% 220M/246M [00:06<00:00, 26.7MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  43% 210M/492M [00:06<00:11, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  85% 210M/246M [00:06<00:01, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   7% 115M/1.72G [00:04<00:58, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  29% 178M/608M [00:05<00:14, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  29% 178M/608M [00:06<00:16, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   4% 147M/3.44G [00:04<01:48, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  22% 273M/1.22G [00:07<00:34, 27.7MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  45% 220M/492M [00:06<00:10, 26.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  94% 231M/246M [00:06<00:00, 26.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  89% 220M/246M [00:06<00:00, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  31% 189M/608M [00:06<00:14, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   7% 126M/1.72G [00:04<01:01, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  31% 189M/608M [00:06<00:15, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   5% 157M/3.44G [00:05<01:51, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  23% 283M/1.22G [00:07<00:31, 29.9MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  47% 231M/492M [00:06<00:09, 28.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  94% 231M/246M [00:06<00:00, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors:  98% 241M/246M [00:07<00:00, 26.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   5% 168M/3.44G [00:05<01:43, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   8% 136M/1.72G [00:05<00:59, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  33% 199M/608M [00:06<00:14, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  33% 199M/608M [00:06<00:15, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  24% 294M/1.22G [00:07<00:32, 28.1MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  49% 241M/492M [00:07<00:08, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading model.fp16.safetensors: 100% 246M/246M [00:07<00:00, 23.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading model.fp16.safetensors: 100% 246M/246M [00:07<00:00, 32.7MB/s]\n","\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   5% 178M/3.44G [00:05<01:50, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  34% 210M/608M [00:07<00:14, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  34% 210M/608M [00:07<00:14, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   9% 147M/1.72G [00:05<00:58, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  25% 304M/1.22G [00:08<00:30, 30.2MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  51% 252M/492M [00:07<00:07, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin: 100% 246M/246M [00:07<00:00, 32.3MB/s]\n","\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  36% 220M/608M [00:07<00:12, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  53% 262M/492M [00:07<00:06, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  26% 315M/1.22G [00:08<00:27, 32.9MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:   9% 157M/1.72G [00:05<00:52, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  36% 220M/608M [00:07<00:14, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   5% 189M/3.44G [00:06<01:58, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  10% 168M/1.72G [00:06<00:49, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  38% 231M/608M [00:07<00:12, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  55% 273M/492M [00:08<00:06, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  27% 325M/1.22G [00:08<00:28, 31.7MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   1% 10.5M/1.72G [00:00<00:43, 38.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)b49d/vae/config.json: 100% 552/552 [00:00<00:00, 2.08MB/s]\n","\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  38% 231M/608M [00:07<00:12, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   6% 199M/3.44G [00:06<01:45, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  58% 283M/492M [00:08<00:06, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  40% 241M/608M [00:08<00:11, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  28% 336M/1.22G [00:09<00:28, 30.5MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  40% 241M/608M [00:08<00:12, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   6% 210M/3.44G [00:06<01:48, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  10% 178M/1.72G [00:06<00:54, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   1% 21.0M/1.72G [00:00<01:13, 23.1MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  60% 294M/492M [00:08<00:06, 30.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   3% 10.5M/335M [00:00<00:07, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  41% 252M/608M [00:08<00:11, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  41% 252M/608M [00:08<00:12, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  28% 346M/1.22G [00:09<00:28, 30.2MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  11% 189M/1.72G [00:06<00:55, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   6% 220M/3.44G [00:07<01:54, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   2% 31.5M/1.72G [00:01<01:04, 26.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  43% 262M/608M [00:08<00:11, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  62% 304M/492M [00:09<00:06, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   6% 21.0M/335M [00:00<00:09, 34.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  43% 262M/608M [00:08<00:12, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  29% 357M/1.22G [00:09<00:30, 28.6MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   7% 231M/3.44G [00:07<01:47, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  12% 199M/1.72G [00:07<00:57, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   2% 41.9M/1.72G [00:01<00:57, 29.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  45% 273M/608M [00:09<00:10, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 31.5M/335M [00:00<00:09, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  64% 315M/492M [00:09<00:06, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   7% 241M/3.44G [00:08<01:50, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  45% 273M/608M [00:09<00:12, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  30% 367M/1.22G [00:10<00:32, 26.3MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  12% 210M/1.72G [00:07<00:56, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   3% 52.4M/1.72G [00:01<00:59, 28.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  13% 41.9M/335M [00:01<00:09, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  47% 283M/608M [00:09<00:10, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  66% 325M/492M [00:09<00:05, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   7% 252M/3.44G [00:08<01:50, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  47% 283M/608M [00:09<00:11, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  13% 220M/1.72G [00:08<00:52, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  31% 377M/1.22G [00:10<00:31, 27.0MB/s]\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  48% 294M/608M [00:09<00:10, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   4% 62.9M/1.72G [00:02<01:03, 26.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  16% 52.4M/335M [00:01<00:09, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  68% 336M/492M [00:10<00:05, 29.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  48% 294M/608M [00:09<00:10, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   8% 262M/3.44G [00:08<01:51, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  32% 388M/1.22G [00:11<00:29, 27.7MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  13% 231M/1.72G [00:08<00:55, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   4% 73.4M/1.72G [00:02<01:00, 27.1MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  70% 346M/492M [00:10<00:04, 30.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  19% 62.9M/335M [00:02<00:09, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  50% 304M/608M [00:10<00:10, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   8% 273M/3.44G [00:09<01:50, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  14% 241M/1.72G [00:08<00:50, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  72% 357M/492M [00:10<00:04, 32.2MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  33% 398M/1.22G [00:11<00:30, 26.9MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  22% 73.4M/335M [00:02<00:08, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  50% 304M/608M [00:10<00:12, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  52% 315M/608M [00:10<00:10, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   5% 83.9M/1.72G [00:03<01:01, 26.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   8% 283M/3.44G [00:09<01:47, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  15% 252M/1.72G [00:09<00:51, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  34% 409M/1.22G [00:11<00:28, 28.4MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  75% 367M/492M [00:11<00:04, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  25% 83.9M/335M [00:02<00:08, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  52% 315M/608M [00:10<00:11, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   5% 94.4M/1.72G [00:03<00:57, 28.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  53% 325M/608M [00:10<00:09, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 294M/3.44G [00:09<01:46, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  15% 262M/1.72G [00:09<00:48, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  34% 419M/1.22G [00:12<00:27, 28.6MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  77% 377M/492M [00:11<00:03, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  55% 336M/608M [00:11<00:08, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  53% 325M/608M [00:11<00:10, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   6% 105M/1.72G [00:03<00:55, 29.2MB/s] \u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  28% 94.4M/335M [00:03<00:08, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 304M/3.44G [00:10<02:45, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  16% 273M/1.72G [00:10<01:22, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  79% 388M/492M [00:12<00:05, 18.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  57% 346M/608M [00:12<00:13, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  31% 105M/335M [00:04<00:12, 18.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  35% 430M/1.22G [00:13<00:45, 17.2MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  55% 336M/608M [00:12<00:15, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   7% 115M/1.72G [00:04<01:33, 17.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 315M/3.44G [00:11<02:40, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  81% 398M/492M [00:13<00:04, 20.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  59% 357M/608M [00:12<00:12, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  34% 115M/335M [00:04<00:10, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  36% 440M/1.22G [00:13<00:39, 19.8MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   7% 126M/1.72G [00:05<01:19, 20.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  16% 283M/1.72G [00:11<01:18, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  57% 346M/608M [00:12<00:13, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  60% 367M/608M [00:12<00:09, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 325M/3.44G [00:11<02:22, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  83% 409M/492M [00:13<00:03, 22.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  38% 126M/335M [00:04<00:09, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  59% 357M/608M [00:13<00:11, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  37% 451M/1.22G [00:14<00:37, 20.6MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   8% 136M/1.72G [00:05<01:13, 21.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  17% 294M/1.72G [00:11<01:09, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  62% 377M/608M [00:13<00:08, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  60% 367M/608M [00:13<00:09, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  85% 419M/492M [00:13<00:03, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  38% 461M/1.22G [00:14<00:31, 24.0MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  10% 336M/3.44G [00:12<02:21, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  41% 136M/335M [00:05<00:08, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  18% 304M/1.72G [00:12<01:06, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   9% 147M/1.72G [00:06<01:11, 22.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  64% 388M/608M [00:13<00:08, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  39% 472M/1.22G [00:14<00:29, 25.5MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  10% 346M/3.44G [00:12<02:11, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  87% 430M/492M [00:14<00:02, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  44% 147M/335M [00:05<00:07, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  62% 377M/608M [00:13<00:10, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  66% 398M/608M [00:13<00:07, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:   9% 157M/1.72G [00:06<01:05, 23.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  18% 315M/1.72G [00:12<01:01, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  89% 440M/492M [00:14<00:01, 28.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  10% 357M/3.44G [00:12<01:53, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  40% 482M/1.22G [00:15<00:38, 19.0MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  92% 451M/492M [00:16<00:03, 10.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  11% 367M/3.44G [00:15<05:00, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  67% 409M/608M [00:16<00:19, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  64% 388M/608M [00:16<00:23, 9.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  19% 325M/1.72G [00:14<02:26, 9.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  10% 168M/1.72G [00:09<02:41, 9.60MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  47% 157M/335M [00:08<00:19, 9.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  41% 493M/1.22G [00:17<01:08, 10.5MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  94% 461M/492M [00:17<00:02, 12.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  11% 377M/3.44G [00:15<04:08, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  20% 336M/1.72G [00:15<01:57, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  10% 178M/1.72G [00:09<02:10, 11.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  50% 168M/335M [00:08<00:14, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  69% 419M/608M [00:17<00:15, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  66% 398M/608M [00:16<00:18, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  41% 503M/1.22G [00:18<00:54, 13.0MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  96% 472M/492M [00:17<00:01, 15.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  11% 388M/3.44G [00:16<03:32, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  67% 409M/608M [00:17<00:15, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  20% 346M/1.72G [00:16<01:50, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  11% 189M/1.72G [00:10<02:03, 12.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  53% 178M/335M [00:09<00:12, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  71% 430M/608M [00:17<00:14, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  42% 514M/1.22G [00:19<01:12, 9.68MB/s]\u001b[A\n","\n","\n","Downloading pytorch_model.bin:  98% 482M/492M [00:20<00:01, 7.26MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  12% 398M/3.44G [00:19<07:00, 7.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  12% 199M/1.72G [00:13<03:30, 7.21MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  72% 440M/608M [00:20<00:23, 7.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  43% 524M/1.22G [00:21<01:28, 7.81MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  69% 419M/608M [00:20<00:27, 6.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  56% 189M/335M [00:12<00:20, 6.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  21% 357M/1.72G [00:19<03:15, 6.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading pytorch_model.bin: 100% 492M/492M [00:21<00:00, 9.03MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  12% 409M/3.44G [00:19<05:28, 9.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  74% 451M/608M [00:20<00:16, 9.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin: 100% 492M/492M [00:21<00:00, 22.7MB/s]\n","\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  71% 430M/608M [00:21<00:20, 8.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  44% 535M/1.22G [00:22<01:11, 9.50MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  21% 367M/1.72G [00:19<02:36, 8.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  60% 199M/335M [00:13<00:15, 8.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  12% 419M/3.44G [00:20<04:20, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  76% 461M/608M [00:21<00:13, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  13% 220M/1.72G [00:14<02:18, 10.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  78% 472M/608M [00:21<00:09, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  13% 430M/3.44G [00:20<03:52, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  22% 377M/1.72G [00:20<02:14, 9.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  63% 210M/335M [00:13<00:12, 9.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  72% 440M/608M [00:21<00:17, 9.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  13% 231M/1.72G [00:14<01:56, 12.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  79% 482M/608M [00:22<00:07, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  45% 545M/1.22G [00:23<01:06, 10.1MB/s]\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  13% 21.0M/167M [00:00<00:04, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  13% 440M/3.44G [00:20<03:05, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  14% 241M/1.72G [00:14<01:28, 16.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  74% 451M/608M [00:22<00:12, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  23% 388M/1.72G [00:20<01:45, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  66% 220M/335M [00:14<00:09, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  19% 31.5M/167M [00:00<00:04, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  46% 556M/1.22G [00:24<01:05, 10.1MB/s]\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  81% 493M/608M [00:25<00:15, 7.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  69% 231M/335M [00:18<00:19, 5.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  76% 461M/608M [00:26<00:27, 5.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  13% 451M/3.44G [00:25<09:03, 5.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  15% 252M/1.72G [00:19<04:22, 5.59MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  23% 398M/1.72G [00:25<04:13, 5.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  47% 566M/1.22G [00:28<01:57, 5.51MB/s]\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  25% 41.9M/167M [00:05<00:23, 5.41MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  83% 503M/608M [00:27<00:15, 6.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  72% 241M/335M [00:18<00:13, 7.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  78% 472M/608M [00:27<00:19, 7.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  13% 461M/3.44G [00:26<06:57, 7.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  31% 52.4M/167M [00:06<00:15, 7.49MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  15% 262M/1.72G [00:20<03:22, 7.19MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  79% 482M/608M [00:27<00:13, 9.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  47% 577M/1.22G [00:28<01:29, 7.15MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  24% 409M/1.72G [00:26<03:15, 6.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  85% 514M/608M [00:27<00:10, 8.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  75% 252M/335M [00:19<00:09, 9.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  14% 472M/3.44G [00:26<05:08, 9.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  38% 62.9M/167M [00:06<00:10, 9.97MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  16% 273M/1.72G [00:20<02:43, 8.86MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  81% 493M/608M [00:28<00:10, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  48% 587M/1.22G [00:29<01:11, 8.76MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  24% 419M/1.72G [00:26<02:39, 8.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  86% 524M/608M [00:28<00:08, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  78% 262M/335M [00:20<00:06, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  14% 482M/3.44G [00:27<04:29, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  44% 73.4M/167M [00:06<00:08, 11.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  16% 283M/1.72G [00:21<02:17, 10.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  83% 503M/608M [00:28<00:08, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  49% 598M/1.22G [00:29<01:00, 10.2MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  25% 430M/1.72G [00:27<02:14, 9.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  88% 535M/608M [00:28<00:06, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  14% 493M/3.44G [00:27<04:04, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  50% 83.9M/167M [00:07<00:06, 13.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  81% 273M/335M [00:20<00:05, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  17% 294M/1.72G [00:21<01:58, 12.0MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  50% 608M/1.22G [00:30<00:50, 12.1MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  84% 514M/608M [00:29<00:06, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  90% 545M/608M [00:29<00:04, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  15% 503M/3.44G [00:28<03:19, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  85% 283M/335M [00:21<00:03, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  26% 440M/1.72G [00:27<01:51, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  56% 94.4M/167M [00:07<00:04, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  18% 304M/1.72G [00:22<01:37, 14.5MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  51% 619M/1.22G [00:30<00:40, 14.7MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  86% 524M/608M [00:29<00:05, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  88% 294M/335M [00:21<00:02, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  15% 514M/3.44G [00:28<02:56, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  91% 556M/608M [00:29<00:03, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  26% 451M/1.72G [00:28<01:33, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  63% 105M/167M [00:08<00:03, 16.1MB/s] \u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  18% 315M/1.72G [00:22<01:26, 16.2MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  52% 629M/1.22G [00:31<00:35, 16.3MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  15% 524M/3.44G [00:28<02:35, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  91% 304M/335M [00:22<00:01, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  27% 461M/1.72G [00:28<01:19, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  88% 535M/608M [00:30<00:04, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  69% 115M/167M [00:08<00:02, 20.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  93% 566M/608M [00:30<00:02, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  53% 640M/1.22G [00:31<00:27, 20.7MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  19% 325M/1.72G [00:22<01:08, 20.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  16% 535M/3.44G [00:29<02:17, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  75% 126M/167M [00:09<00:01, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  90% 545M/608M [00:30<00:03, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  27% 472M/1.72G [00:29<01:11, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  95% 577M/608M [00:30<00:01, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  53% 650M/1.22G [00:31<00:26, 21.5MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  94% 315M/335M [00:22<00:01, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  20% 336M/1.72G [00:23<01:06, 20.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  16% 545M/3.44G [00:29<02:33, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  81% 136M/167M [00:10<00:01, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  54% 661M/1.22G [00:32<00:34, 15.9MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  28% 482M/1.72G [00:30<01:32, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  91% 556M/608M [00:31<00:03, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  97% 325M/335M [00:23<00:00, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  97% 587M/608M [00:32<00:01, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  20% 346M/1.72G [00:24<01:38, 14.0MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  88% 147M/167M [00:10<00:01, 17.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  16% 556M/3.44G [00:30<03:04, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  55% 671M/1.22G [00:33<00:30, 18.0MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  29% 493M/1.72G [00:30<01:19, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  93% 566M/608M [00:32<00:02, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin: 100% 335M/335M [00:24<00:00, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors:  98% 598M/608M [00:32<00:00, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin:  94% 157M/167M [00:10<00:00, 20.7MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  56% 682M/1.22G [00:33<00:24, 21.8MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  16% 566M/3.44G [00:31<02:33, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  21% 357M/1.72G [00:25<01:26, 15.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin: 100% 335M/335M [00:26<00:00, 12.4MB/s]\n","\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  29% 503M/1.72G [00:33<02:36, 7.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors: 100% 608M/608M [00:35<00:00, 7.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  21% 367M/1.72G [00:27<02:50, 7.92MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  57% 692M/1.22G [00:36<01:01, 8.49MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  17% 577M/3.44G [00:34<05:50, 8.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)torch_model.fp16.bin: 100% 167M/167M [00:13<00:00, 8.13MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  30% 514M/1.72G [00:33<01:59, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading model.fp16.safetensors: 100% 608M/608M [00:35<00:00, 17.1MB/s]\n","Fetching 24 files:  21% 5/24 [00:38<03:39, 11.57s/it]\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  13% 21.0M/167M [00:00<00:01, 99.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)torch_model.fp16.bin: 100% 167M/167M [00:14<00:00, 11.7MB/s]\n","\n","Downloading pytorch_model.bin:  58% 703M/1.22G [00:36<00:47, 10.7MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  30% 524M/1.72G [00:34<01:33, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  17% 587M/3.44G [00:34<04:36, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin:  98% 598M/608M [00:35<00:00, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  23% 388M/1.72G [00:28<01:41, 13.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  19% 31.5M/167M [00:00<00:02, 51.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  59% 713M/1.22G [00:37<00:37, 13.5MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  31% 535M/1.72G [00:34<01:14, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","Downloading pytorch_model.fp16.bin: 100% 608M/608M [00:36<00:00, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  23% 398M/1.72G [00:28<01:15, 17.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  17% 598M/3.44G [00:34<03:39, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.fp16.bin: 100% 608M/608M [00:36<00:00, 16.8MB/s]\n","\n","\n","Downloading (…)del.fp16.safetensors:  24% 409M/1.72G [00:28<01:00, 21.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  32% 545M/1.72G [00:34<01:02, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  18% 608M/3.44G [00:35<02:55, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  59% 724M/1.22G [00:37<00:30, 16.1MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  31% 52.4M/167M [00:00<00:02, 50.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  24% 419M/1.72G [00:28<00:46, 27.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  32% 556M/1.72G [00:34<00:48, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  18% 619M/3.44G [00:35<02:18, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  60% 734M/1.22G [00:37<00:23, 20.2MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  25% 430M/1.72G [00:29<00:41, 31.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  38% 62.9M/167M [00:01<00:02, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  33% 566M/1.72G [00:35<00:39, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  61% 744M/1.22G [00:37<00:18, 25.8MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  18% 629M/3.44G [00:35<01:51, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  26% 440M/1.72G [00:29<00:36, 34.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  34% 577M/1.72G [00:35<00:33, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  44% 73.4M/167M [00:01<00:02, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  62% 755M/1.22G [00:38<00:15, 29.2MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  19% 640M/3.44G [00:35<01:37, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  26% 451M/1.72G [00:29<00:33, 37.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  50% 83.9M/167M [00:01<00:01, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  34% 587M/1.72G [00:35<00:31, 35.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  63% 765M/1.22G [00:38<00:13, 33.5MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  19% 650M/3.44G [00:36<01:24, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  27% 461M/1.72G [00:29<00:31, 39.5MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  64% 776M/1.22G [00:38<00:11, 38.8MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  35% 598M/1.72G [00:35<00:30, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  56% 94.4M/167M [00:02<00:01, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  19% 661M/3.44G [00:36<01:19, 34.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  27% 472M/1.72G [00:30<00:27, 45.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  35% 608M/1.72G [00:36<00:26, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  20% 671M/3.44G [00:36<01:11, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  65% 786M/1.22G [00:38<00:11, 36.5MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  63% 105M/167M [00:02<00:01, 40.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  28% 482M/1.72G [00:30<00:27, 44.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  36% 619M/1.72G [00:36<00:25, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  20% 682M/3.44G [00:36<01:05, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  69% 115M/167M [00:02<00:01, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  66% 797M/1.22G [00:38<00:10, 38.6MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  29% 493M/1.72G [00:30<00:26, 45.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  37% 629M/1.72G [00:36<00:22, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  20% 692M/3.44G [00:36<00:59, 46.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  66% 807M/1.22G [00:39<00:09, 44.8MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  75% 126M/167M [00:02<00:00, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  29% 503M/1.72G [00:30<00:29, 40.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  20% 703M/3.44G [00:37<01:06, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  67% 818M/1.22G [00:39<00:09, 41.0MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  37% 640M/1.72G [00:36<00:29, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  81% 136M/167M [00:03<00:00, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  30% 514M/1.72G [00:31<00:27, 43.7MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  68% 828M/1.22G [00:42<00:38, 10.2MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  21% 713M/3.44G [00:40<04:32, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  88% 147M/167M [00:05<00:02, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  38% 650M/1.72G [00:39<01:51, 9.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  21% 724M/3.44G [00:40<03:21, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  30% 524M/1.72G [00:33<02:00, 9.91MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  69% 839M/1.22G [00:42<00:28, 13.1MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors:  94% 157M/167M [00:06<00:00, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  21% 734M/3.44G [00:40<02:33, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  38% 661M/1.72G [00:40<01:23, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  31% 535M/1.72G [00:34<01:34, 12.6MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  70% 849M/1.22G [00:42<00:22, 16.4MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:06<00:00, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  22% 744M/3.44G [00:41<03:11, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  39% 671M/1.72G [00:41<01:36, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  32% 545M/1.72G [00:38<03:32, 5.53MB/s]\u001b[A\u001b[A\n","Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:10<00:00, 15.2MB/s]\n","\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  22% 755M/3.44G [00:45<07:04, 6.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  32% 556M/1.72G [00:39<02:44, 7.09MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  22% 765M/3.44G [00:45<05:07, 8.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  72% 870M/1.22G [00:47<00:44, 7.69MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  23% 776M/3.44G [00:45<03:48, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  33% 566M/1.72G [00:39<02:00, 9.58MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  40% 682M/1.72G [00:45<03:03, 5.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  72% 881M/1.22G [00:47<00:32, 10.5MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  40% 692M/1.72G [00:45<02:12, 7.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  23% 786M/3.44G [00:45<02:54, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  73% 891M/1.22G [00:48<00:23, 13.8MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  34% 577M/1.72G [00:39<01:30, 12.6MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  74% 902M/1.22G [00:48<00:17, 18.4MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  34% 587M/1.72G [00:39<01:08, 16.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  41% 703M/1.72G [00:45<01:37, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  23% 797M/3.44G [00:46<02:19, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  75% 912M/1.22G [00:48<00:12, 23.8MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  35% 598M/1.72G [00:40<01:06, 16.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  41% 713M/1.72G [00:46<01:26, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  23% 807M/3.44G [00:46<02:23, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  76% 923M/1.22G [00:48<00:13, 21.3MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  42% 724M/1.72G [00:48<02:06, 7.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  24% 818M/3.44G [00:49<04:35, 9.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  35% 608M/1.72G [00:42<02:02, 9.07MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  77% 933M/1.22G [00:51<00:27, 10.1MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  36% 619M/1.72G [00:42<01:28, 12.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  43% 734M/1.72G [00:48<01:31, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  24% 828M/3.44G [00:49<03:24, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  78% 944M/1.22G [00:51<00:20, 13.4MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  37% 629M/1.72G [00:43<01:20, 13.5MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  78% 954M/1.22G [00:52<00:19, 13.5MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  43% 744M/1.72G [00:49<01:27, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  24% 839M/3.44G [00:50<03:24, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  37% 640M/1.72G [00:43<01:06, 16.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  25% 849M/3.44G [00:50<02:35, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  79% 965M/1.22G [00:52<00:15, 16.4MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  38% 661M/1.72G [00:44<00:41, 25.7MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  39% 671M/1.72G [00:44<00:34, 30.7MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  81% 986M/1.22G [00:52<00:08, 26.5MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  45% 765M/1.72G [00:50<00:58, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  25% 870M/3.44G [00:50<01:53, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  82% 996M/1.22G [00:53<00:09, 23.6MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  40% 682M/1.72G [00:44<00:40, 25.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  45% 776M/1.72G [00:51<01:05, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  26% 881M/3.44G [00:52<02:56, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  83% 1.01G/1.22G [00:57<00:27, 7.61MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  26% 891M/3.44G [00:55<05:14, 8.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  46% 786M/1.72G [00:54<02:11, 7.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  84% 1.02G/1.22G [00:57<00:19, 9.97MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  40% 692M/1.72G [00:49<02:22, 7.20MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  26% 902M/3.44G [00:55<04:01, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  27% 912M/3.44G [00:55<03:12, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  41% 703M/1.72G [00:49<01:49, 9.25MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  86% 1.05G/1.22G [00:57<00:08, 19.0MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  46% 797M/1.72G [00:55<01:49, 8.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  41% 713M/1.72G [00:49<01:23, 12.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  27% 923M/3.44G [00:55<02:33, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  87% 1.06G/1.22G [00:58<00:07, 21.6MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  47% 807M/1.72G [00:55<01:21, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  88% 1.07G/1.22G [00:58<00:05, 26.3MB/s]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  48% 818M/1.72G [00:55<01:00, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  43% 734M/1.72G [00:49<00:50, 19.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  27% 944M/3.44G [00:56<01:39, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  89% 1.08G/1.22G [00:58<00:04, 30.2MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  43% 744M/1.72G [00:49<00:40, 23.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  48% 828M/1.72G [00:55<00:46, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  28% 954M/3.44G [00:56<01:24, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  90% 1.09G/1.22G [00:58<00:03, 33.9MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  44% 755M/1.72G [00:50<00:33, 28.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  49% 839M/1.72G [00:56<00:36, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  28% 965M/3.44G [00:56<01:08, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  91% 1.10G/1.22G [00:58<00:03, 38.2MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  45% 765M/1.72G [00:50<00:28, 33.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  49% 849M/1.72G [00:56<00:30, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  28% 975M/3.44G [00:56<01:02, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  91% 1.11G/1.22G [00:58<00:02, 43.8MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  45% 776M/1.72G [00:50<00:25, 37.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  50% 860M/1.72G [00:56<00:25, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  92% 1.12G/1.22G [00:59<00:01, 49.8MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  29% 986M/3.44G [00:56<01:01, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  46% 786M/1.72G [00:50<00:21, 42.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  51% 870M/1.72G [00:56<00:21, 39.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  93% 1.13G/1.22G [00:59<00:01, 55.1MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  29% 996M/3.44G [00:57<00:53, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  51% 881M/1.72G [00:56<00:18, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  46% 797M/1.72G [00:50<00:19, 46.4MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  94% 1.14G/1.22G [00:59<00:01, 59.6MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  29% 1.01G/3.44G [00:57<00:52, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  52% 891M/1.72G [00:56<00:17, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  95% 1.15G/1.22G [00:59<00:01, 58.4MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  47% 807M/1.72G [00:51<00:19, 47.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  30% 1.02G/3.44G [00:57<00:46, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  52% 902M/1.72G [00:57<00:15, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  97% 1.17G/1.22G [00:59<00:00, 73.7MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  48% 818M/1.72G [00:51<00:18, 47.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  53% 912M/1.72G [00:57<00:18, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  30% 1.03G/3.44G [00:57<01:00, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  97% 1.18G/1.22G [01:01<00:01, 22.4MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  48% 828M/1.72G [00:52<00:51, 17.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  54% 923M/1.72G [00:59<01:04, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  30% 1.04G/3.44G [01:00<03:17, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  98% 1.20G/1.22G [01:02<00:01, 16.2MB/s]\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  49% 839M/1.72G [00:53<01:04, 13.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  54% 933M/1.72G [00:59<00:49, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  55% 944M/1.72G [01:00<00:36, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  30% 1.05G/3.44G [01:00<02:43, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  50% 860M/1.72G [00:54<00:38, 22.0MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  99% 1.21G/1.22G [01:02<00:00, 18.5MB/s]\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  31% 1.06G/3.44G [01:00<02:08, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  56% 965M/1.72G [01:00<00:24, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin: 100% 1.22G/1.22G [01:02<00:00, 21.5MB/s]\u001b[A\n","\n","Downloading pytorch_model.bin: 100% 1.22G/1.22G [01:03<00:00, 19.3MB/s]\n","\n","\n","\n","\n","\n","Fetching 24 files:  25% 6/24 [01:04<04:50, 16.13s/it]\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  57% 975M/1.72G [01:00<00:21, 35.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  51% 881M/1.72G [00:54<00:28, 29.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  31% 1.08G/3.44G [01:00<01:17, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  52% 891M/1.72G [00:54<00:23, 34.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  32% 1.09G/3.44G [01:01<01:03, 37.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  58% 996M/1.72G [01:00<00:15, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  52% 902M/1.72G [00:54<00:20, 40.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  32% 1.10G/3.44G [01:01<00:58, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  59% 1.01G/1.72G [01:01<00:18, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  53% 912M/1.72G [00:56<00:37, 21.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  32% 1.11G/3.44G [01:03<02:47, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  59% 1.02G/1.72G [01:04<01:12, 9.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  54% 923M/1.72G [00:58<01:29, 8.92MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  33% 1.12G/3.44G [01:05<04:05, 9.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  60% 1.04G/1.72G [01:04<00:43, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  61% 1.05G/1.72G [01:05<00:35, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  33% 1.13G/3.44G [01:05<03:11, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  55% 944M/1.72G [00:59<00:54, 14.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  34% 1.15G/3.44G [01:05<01:56, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  56% 954M/1.72G [00:59<00:47, 16.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  63% 1.08G/1.72G [01:05<00:22, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  34% 1.16G/3.44G [01:05<01:39, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  63% 1.09G/1.72G [01:05<00:19, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  34% 1.17G/3.44G [01:06<01:20, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  56% 965M/1.72G [00:59<00:37, 19.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  64% 1.10G/1.72G [01:05<00:16, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  35% 1.20G/3.44G [01:06<00:52, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  57% 986M/1.72G [01:00<00:23, 30.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  65% 1.11G/1.72G [01:05<00:14, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  35% 1.21G/3.44G [01:06<00:45, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  58% 996M/1.72G [01:00<00:20, 35.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  35% 1.22G/3.44G [01:06<00:40, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  66% 1.13G/1.72G [01:06<00:10, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  59% 1.01G/1.72G [01:00<00:18, 39.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  36% 1.23G/3.44G [01:06<00:38, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  66% 1.14G/1.72G [01:06<00:09, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  67% 1.15G/1.72G [01:06<00:09, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  60% 1.03G/1.72G [01:00<00:13, 52.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  36% 1.25G/3.44G [01:06<00:35, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  68% 1.16G/1.72G [01:06<00:08, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  60% 1.04G/1.72G [01:00<00:11, 57.2MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  61% 1.05G/1.72G [01:00<00:10, 61.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  37% 1.27G/3.44G [01:07<00:29, 74.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  62% 1.06G/1.72G [01:01<00:11, 58.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  68% 1.17G/1.72G [01:06<00:11, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  37% 1.28G/3.44G [01:07<00:38, 55.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  62% 1.07G/1.72G [01:01<00:14, 44.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  69% 1.18G/1.72G [01:08<00:28, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  38% 1.29G/3.44G [01:10<02:35, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  70% 1.20G/1.72G [01:09<00:39, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  63% 1.08G/1.72G [01:03<00:52, 12.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  70% 1.21G/1.72G [01:09<00:28, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  38% 1.31G/3.44G [01:10<01:39, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  63% 1.09G/1.72G [01:04<00:39, 15.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  71% 1.22G/1.72G [01:10<00:21, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  38% 1.32G/3.44G [01:10<01:22, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  64% 1.10G/1.72G [01:04<00:32, 19.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  39% 1.33G/3.44G [01:10<01:12, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  72% 1.24G/1.72G [01:10<00:14, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  39% 1.34G/3.44G [01:10<00:59, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  65% 1.11G/1.72G [01:04<00:26, 23.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  73% 1.26G/1.72G [01:10<00:09, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  65% 1.12G/1.72G [01:04<00:22, 26.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  74% 1.27G/1.72G [01:10<00:10, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  40% 1.36G/3.44G [01:11<00:51, 40.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  66% 1.13G/1.72G [01:08<01:21, 7.18MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  74% 1.28G/1.72G [01:14<00:47, 9.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  40% 1.37G/3.44G [01:15<03:41, 9.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  66% 1.14G/1.72G [01:08<00:58, 9.88MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  67% 1.15G/1.72G [01:09<00:41, 13.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  40% 1.38G/3.44G [01:15<02:55, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  75% 1.29G/1.72G [01:15<00:37, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  41% 1.39G/3.44G [01:15<02:13, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  68% 1.17G/1.72G [01:09<00:23, 22.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  76% 1.30G/1.72G [01:15<00:27, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  41% 1.41G/3.44G [01:15<01:49, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  76% 1.31G/1.72G [01:15<00:22, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  69% 1.18G/1.72G [01:09<00:22, 24.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  41% 1.43G/3.44G [01:15<01:11, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  70% 1.20G/1.72G [01:09<00:17, 29.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  77% 1.33G/1.72G [01:15<00:13, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  70% 1.21G/1.72G [01:09<00:14, 35.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  42% 1.44G/3.44G [01:16<01:01, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  78% 1.34G/1.72G [01:15<00:11, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  71% 1.22G/1.72G [01:09<00:11, 43.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  42% 1.45G/3.44G [01:16<00:51, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  79% 1.35G/1.72G [01:15<00:09, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  71% 1.23G/1.72G [01:10<00:09, 52.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  42% 1.46G/3.44G [01:16<00:44, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  72% 1.24G/1.72G [01:10<00:08, 59.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  79% 1.36G/1.72G [01:16<00:08, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  43% 1.47G/3.44G [01:16<00:38, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  73% 1.25G/1.72G [01:10<00:07, 63.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  80% 1.37G/1.72G [01:16<00:07, 48.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  43% 1.48G/3.44G [01:16<00:35, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  73% 1.26G/1.72G [01:10<00:06, 67.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  81% 1.38G/1.72G [01:16<00:06, 55.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  43% 1.49G/3.44G [01:16<00:31, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  74% 1.27G/1.72G [01:10<00:06, 73.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  81% 1.39G/1.72G [01:16<00:05, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  44% 1.50G/3.44G [01:16<00:29, 65.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  82% 1.41G/1.72G [01:16<00:05, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  74% 1.28G/1.72G [01:10<00:06, 67.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  44% 1.51G/3.44G [01:16<00:26, 73.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  82% 1.42G/1.72G [01:17<00:07, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  75% 1.29G/1.72G [01:11<00:12, 35.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  44% 1.52G/3.44G [01:18<01:22, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  83% 1.43G/1.72G [01:18<00:16, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  76% 1.30G/1.72G [01:12<00:23, 18.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  84% 1.44G/1.72G [01:18<00:12, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  45% 1.53G/3.44G [01:18<01:38, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  76% 1.31G/1.72G [01:12<00:17, 23.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  45% 1.54G/3.44G [01:19<01:18, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  84% 1.45G/1.72G [01:18<00:09, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  77% 1.32G/1.72G [01:12<00:14, 27.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  45% 1.55G/3.44G [01:19<01:02, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  85% 1.46G/1.72G [01:18<00:07, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  77% 1.33G/1.72G [01:13<00:11, 33.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  45% 1.56G/3.44G [01:19<01:00, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  85% 1.47G/1.72G [01:19<00:08, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  78% 1.34G/1.72G [01:13<00:11, 32.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  46% 1.57G/3.44G [01:20<01:07, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  86% 1.48G/1.72G [01:19<00:08, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  79% 1.35G/1.72G [01:13<00:11, 30.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  87% 1.49G/1.72G [01:19<00:06, 38.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  46% 1.58G/3.44G [01:20<00:54, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  87% 1.50G/1.72G [01:19<00:04, 45.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  79% 1.36G/1.72G [01:14<00:10, 33.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  46% 1.59G/3.44G [01:20<00:45, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  47% 1.60G/3.44G [01:20<00:38, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  81% 1.38G/1.72G [01:14<00:07, 46.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  88% 1.52G/1.72G [01:20<00:03, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  47% 1.61G/3.44G [01:20<00:34, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  81% 1.39G/1.72G [01:14<00:06, 51.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  89% 1.53G/1.72G [01:20<00:03, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  47% 1.63G/3.44G [01:20<00:33, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  82% 1.41G/1.72G [01:14<00:05, 56.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  48% 1.64G/3.44G [01:20<00:29, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  90% 1.54G/1.72G [01:20<00:03, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  82% 1.42G/1.72G [01:14<00:04, 64.4MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  83% 1.43G/1.72G [01:14<00:04, 66.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  90% 1.55G/1.72G [01:20<00:02, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  48% 1.66G/3.44G [01:21<00:25, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  91% 1.56G/1.72G [01:20<00:02, 65.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  84% 1.44G/1.72G [01:15<00:04, 65.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  48% 1.67G/3.44G [01:21<00:25, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  84% 1.45G/1.72G [01:15<00:03, 71.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  92% 1.58G/1.72G [01:21<00:01, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  49% 1.68G/3.44G [01:21<00:25, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  85% 1.46G/1.72G [01:15<00:03, 76.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  49% 1.69G/3.44G [01:21<00:24, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  93% 1.60G/1.72G [01:21<00:01, 83.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  85% 1.47G/1.72G [01:15<00:03, 72.2MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  86% 1.48G/1.72G [01:15<00:03, 76.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  50% 1.71G/3.44G [01:21<00:20, 86.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  95% 1.63G/1.72G [01:21<00:01, 90.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  87% 1.49G/1.72G [01:15<00:02, 78.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  50% 1.72G/3.44G [01:21<00:20, 82.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  95% 1.64G/1.72G [01:21<00:00, 86.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  50% 1.73G/3.44G [01:22<00:21, 78.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  96% 1.65G/1.72G [01:21<00:00, 86.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  88% 1.51G/1.72G [01:15<00:02, 85.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  96% 1.66G/1.72G [01:21<00:00, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  51% 1.74G/3.44G [01:22<00:21, 78.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  88% 1.52G/1.72G [01:15<00:02, 87.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  97% 1.67G/1.72G [01:22<00:00, 88.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  51% 1.75G/3.44G [01:22<00:20, 80.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  89% 1.53G/1.72G [01:16<00:02, 87.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  51% 1.76G/3.44G [01:22<00:21, 76.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  90% 1.54G/1.72G [01:16<00:02, 81.4MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  98% 1.68G/1.72G [01:22<00:00, 81.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  98% 1.69G/1.72G [01:22<00:00, 83.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  90% 1.55G/1.72G [01:16<00:02, 79.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  52% 1.77G/3.44G [01:22<00:22, 74.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  99% 1.70G/1.72G [01:22<00:00, 87.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  91% 1.56G/1.72G [01:16<00:01, 84.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  52% 1.78G/3.44G [01:22<00:20, 79.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  52% 1.79G/3.44G [01:22<00:20, 80.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin:  99% 1.71G/1.72G [01:22<00:00, 78.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  91% 1.57G/1.72G [01:16<00:01, 79.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  52% 1.80G/3.44G [01:22<00:19, 83.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  92% 1.58G/1.72G [01:16<00:01, 82.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","Downloading (…)torch_model.fp16.bin: 100% 1.72G/1.72G [01:22<00:00, 20.8MB/s]\n","\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  53% 1.81G/3.44G [01:23<00:18, 88.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  93% 1.59G/1.72G [01:16<00:01, 84.2MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  93% 1.60G/1.72G [01:17<00:01, 83.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  53% 1.84G/3.44G [01:23<00:27, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  94% 1.61G/1.72G [01:18<00:05, 20.7MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  54% 1.85G/3.44G [01:24<01:12, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  95% 1.63G/1.72G [01:18<00:04, 22.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  54% 1.87G/3.44G [01:25<00:47, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  96% 1.65G/1.72G [01:18<00:02, 35.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  55% 1.88G/3.44G [01:25<00:40, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  96% 1.66G/1.72G [01:19<00:01, 41.8MB/s]\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  98% 1.68G/1.72G [01:19<00:00, 61.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  55% 1.90G/3.44G [01:25<00:32, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors:  99% 1.70G/1.72G [01:19<00:00, 78.6MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  56% 1.91G/3.44G [01:25<00:28, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading (…)del.fp16.safetensors: 100% 1.72G/1.72G [01:19<00:00, 88.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)del.fp16.safetensors: 100% 1.72G/1.72G [01:19<00:00, 21.5MB/s]\n","\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  56% 1.93G/3.44G [01:30<02:53, 8.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  57% 1.95G/3.44G [01:30<01:42, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  58% 1.98G/3.44G [01:30<00:55, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  59% 2.02G/3.44G [01:30<00:32, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  60% 2.06G/3.44G [01:30<00:24, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  61% 2.09G/3.44G [01:30<00:17, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  62% 2.13G/3.44G [01:31<00:13, 96.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  63% 2.17G/3.44G [01:31<00:10, 126MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  64% 2.20G/3.44G [01:32<00:16, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  65% 2.22G/3.44G [01:36<00:59, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  66% 2.25G/3.44G [01:36<00:41, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  66% 2.28G/3.44G [01:36<00:34, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  67% 2.30G/3.44G [01:36<00:28, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  67% 2.32G/3.44G [01:36<00:23, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  68% 2.35G/3.44G [01:36<00:16, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  69% 2.38G/3.44G [01:37<00:12, 87.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  70% 2.40G/3.44G [01:37<00:10, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  71% 2.43G/3.44G [01:37<00:07, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  71% 2.45G/3.44G [01:37<00:07, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  72% 2.49G/3.44G [01:37<00:05, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  73% 2.52G/3.44G [01:37<00:05, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  74% 2.55G/3.44G [01:38<00:10, 85.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  75% 2.57G/3.44G [01:43<00:52, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  76% 2.60G/3.44G [01:43<00:35, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  77% 2.63G/3.44G [01:43<00:23, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  77% 2.65G/3.44G [01:43<00:18, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  78% 2.67G/3.44G [01:43<00:14, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  78% 2.69G/3.44G [01:43<00:11, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  79% 2.72G/3.44G [01:43<00:09, 76.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  80% 2.75G/3.44G [01:43<00:06, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  81% 2.78G/3.44G [01:44<00:04, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  82% 2.81G/3.44G [01:44<00:03, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  83% 2.84G/3.44G [01:44<00:03, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  84% 2.87G/3.44G [01:44<00:03, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  84% 2.90G/3.44G [01:44<00:02, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  85% 2.94G/3.44G [01:44<00:02, 187MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  86% 2.96G/3.44G [01:44<00:02, 169MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  87% 2.98G/3.44G [01:47<00:15, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  87% 3.00G/3.44G [01:47<00:11, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  88% 3.02G/3.44G [01:47<00:09, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  89% 3.06G/3.44G [01:48<00:05, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  90% 3.09G/3.44G [01:48<00:03, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  91% 3.11G/3.44G [01:48<00:03, 99.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  91% 3.15G/3.44G [01:48<00:02, 126MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  92% 3.18G/3.44G [01:48<00:01, 151MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  93% 3.21G/3.44G [01:48<00:01, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  94% 3.24G/3.44G [01:48<00:01, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  95% 3.27G/3.44G [01:49<00:01, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  96% 3.29G/3.44G [01:49<00:00, 165MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  96% 3.31G/3.44G [01:49<00:00, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  97% 3.34G/3.44G [01:49<00:00, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  98% 3.38G/3.44G [01:49<00:00, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  99% 3.41G/3.44G [01:49<00:00, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin: 100% 3.44G/3.44G [01:49<00:00, 31.3MB/s]\n","Fetching 24 files: 100% 24/24 [01:54<00:00,  4.75s/it]\n","`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n","`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n","`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n","2023-09-30T08:44:11+0000 [ERROR] [cli] Exception in callback <bound method Arbiter.manage_watchers of <circus.arbiter.Arbiter object at 0x78243c7ef7c0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 919, in _run\n","    val = self.callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/circus/util.py\", line 1038, in wrapper\n","    raise ConflictError(\"arbiter is already running %s command\"\n","circus.exc.ConflictError: arbiter is already running arbiter_stop command\n","^C\n"]}]},{"cell_type":"code","source":["!pip install diffusers pathlib"],"metadata":{"id":"T3Mz2sqASynT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696071649831,"user_tz":-420,"elapsed":11791,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"c1d09c64-b6f7-412d-c419-a2cf9c58ebbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting diffusers\n","  Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.12.2)\n","Collecting huggingface-hub>=0.13.2 (from diffusers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n","Collecting safetensors>=0.3.1 (from diffusers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (23.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.16.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, diffusers\n","Successfully installed diffusers-0.21.4 huggingface-hub-0.17.3 safetensors-0.3.3\n"]}]},{"cell_type":"code","source":["import cv2\n","from matplotlib import pyplot as plt\n","import PIL.Image as Image\n","import numpy as np\n","\n","\n","def crop_for_filling_pre(image, mask, crop_size: int = 512):\n","    # Calculate the aspect ratio of the image\n","    height, width = image.shape[:2]\n","    aspect_ratio = float(width) / float(height)\n","\n","    # If the shorter side is less than 512, resize the image proportionally\n","    if min(height, width) < crop_size:\n","        if height < width:\n","            new_height = crop_size\n","            new_width = int(new_height * aspect_ratio)\n","        else:\n","            new_width = crop_size\n","            new_height = int(new_width / aspect_ratio)\n","\n","        image = cv2.resize(image, (new_width, new_height))\n","        mask = cv2.resize(mask, (new_width, new_height))\n","\n","    # Find the bounding box of the mask\n","    x, y, w, h = cv2.boundingRect(mask)\n","\n","    # Update the height and width of the resized image\n","    height, width = image.shape[:2]\n","\n","    # # If the 512x512 square cannot cover the entire mask, resize the image accordingly\n","    if w > crop_size or h > crop_size:\n","        # padding to square at first\n","        if height < width:\n","            padding = width - height\n","            image = np.pad(image, ((padding // 2, padding - padding // 2), (0, 0), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","        else:\n","            padding = height - width\n","            image = np.pad(image, ((0, 0), (padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((0, 0), (padding // 2, padding - padding // 2)), 'constant')\n","\n","        resize_factor = crop_size / max(w, h)\n","        image = cv2.resize(image, (0, 0), fx=resize_factor, fy=resize_factor)\n","        mask = cv2.resize(mask, (0, 0), fx=resize_factor, fy=resize_factor)\n","        x, y, w, h = cv2.boundingRect(mask)\n","\n","    # Calculate the crop coordinates\n","    crop_x = min(max(x + w // 2 - crop_size // 2, 0), width - crop_size)\n","    crop_y = min(max(y + h // 2 - crop_size // 2, 0), height - crop_size)\n","\n","    # Crop the image\n","    cropped_image = image[crop_y:crop_y + crop_size, crop_x:crop_x + crop_size]\n","    cropped_mask = mask[crop_y:crop_y + crop_size, crop_x:crop_x + crop_size]\n","\n","    return cropped_image, cropped_mask\n","\n","\n","def crop_for_filling_post(\n","        image: np.array,\n","        mask: np.array,\n","        filled_image: np.array,\n","        crop_size: int = 512,\n","        ):\n","    image_copy = image.copy()\n","    mask_copy = mask.copy()\n","    # Calculate the aspect ratio of the image\n","    height, width = image.shape[:2]\n","    height_ori, width_ori = height, width\n","    aspect_ratio = float(width) / float(height)\n","\n","    # If the shorter side is less than 512, resize the image proportionally\n","    if min(height, width) < crop_size:\n","        if height < width:\n","            new_height = crop_size\n","            new_width = int(new_height * aspect_ratio)\n","        else:\n","            new_width = crop_size\n","            new_height = int(new_width / aspect_ratio)\n","\n","        image = cv2.resize(image, (new_width, new_height))\n","        mask = cv2.resize(mask, (new_width, new_height))\n","\n","    # Find the bounding box of the mask\n","    x, y, w, h = cv2.boundingRect(mask)\n","\n","    # Update the height and width of the resized image\n","    height, width = image.shape[:2]\n","\n","    # # If the 512x512 square cannot cover the entire mask, resize the image accordingly\n","    if w > crop_size or h > crop_size:\n","        flag_padding = True\n","        # padding to square at first\n","        if height < width:\n","            padding = width - height\n","            image = np.pad(image, ((padding // 2, padding - padding // 2), (0, 0), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","            padding_side = 'h'\n","        else:\n","            padding = height - width\n","            image = np.pad(image, ((0, 0), (padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((0, 0), (padding // 2, padding - padding // 2)), 'constant')\n","            padding_side = 'w'\n","\n","        resize_factor = crop_size / max(w, h)\n","        image = cv2.resize(image, (0, 0), fx=resize_factor, fy=resize_factor)\n","        mask = cv2.resize(mask, (0, 0), fx=resize_factor, fy=resize_factor)\n","        x, y, w, h = cv2.boundingRect(mask)\n","    else:\n","        flag_padding = False\n","\n","    # Calculate the crop coordinates\n","    crop_x = min(max(x + w // 2 - crop_size // 2, 0), width - crop_size)\n","    crop_y = min(max(y + h // 2 - crop_size // 2, 0), height - crop_size)\n","\n","    # Fill the image\n","    image[crop_y:crop_y + crop_size, crop_x:crop_x + crop_size] = filled_image\n","    if flag_padding:\n","        image = cv2.resize(image, (0, 0), fx=1/resize_factor, fy=1/resize_factor)\n","        if padding_side == 'h':\n","            image = image[padding // 2:padding // 2 + height_ori, :]\n","        else:\n","            image = image[:, padding // 2:padding // 2 + width_ori]\n","\n","    image = cv2.resize(image, (width_ori, height_ori))\n","\n","    image_copy[mask_copy==255] = image[mask_copy==255]\n","    return image_copy\n","\n","\n","if __name__ == '__main__':\n","\n","    # image = cv2.imread('example/boat.jpg')\n","    # mask = cv2.imread('example/boat_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","    image = cv2.imread('/content/input.png')\n","    mask = cv2.imread('/content/mask.png', cv2.IMREAD_GRAYSCALE)\n","    # image = cv2.imread('example/bridge.jpg')\n","    # mask = cv2.imread('example/bridge_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","    # image = cv2.imread('example/person_umbrella.jpg')\n","    # mask = cv2.imread('example/person_umbrella_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","    # image = cv2.imread('example/hippopotamus.jpg')\n","    # mask = cv2.imread('example/hippopotamus_mask_1.png', cv2.IMREAD_GRAYSCALE)\n","\n","    cropped_image, cropped_mask = crop_for_filling_pre(image, mask)\n","    # ^ ------------------------------------------------------------------------------------\n","    # ^ Please conduct inpainting or filling here on the cropped image with the cropped mask\n","    # ^ ------------------------------------------------------------------------------------\n","\n","    # e.g.\n","    # cropped_image[cropped_mask==255] = 0\n","    cv2.imwrite('cropped_image.jpg', cropped_image)\n","    cv2.imwrite('cropped_mask.jpg', cropped_mask)\n","    print(cropped_image.shape)\n","    print(cropped_mask.shape)\n","\n","    image = crop_for_filling_post(image, mask, cropped_image)\n","    cv2.imwrite('filled_image.jpg', image)\n","    print(image.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"MFg5oAPcTGaq","executionInfo":{"status":"error","timestamp":1696153883323,"user_tz":-420,"elapsed":374,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"fef71ee1-48fd-4211-d57b-39060b3f0df6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(512, 512, 3)\n","(512, 512)\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-7c827ada9160>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_for_filling_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropped_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filled_image.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-7c827ada9160>\u001b[0m in \u001b[0;36mcrop_for_filling_post\u001b[0;34m(image, mask, filled_image, crop_size)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth_ori\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_ori\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mimage_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_copy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_copy\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 550 but corresponding boolean dimension is 512"]}]},{"cell_type":"code","source":[],"metadata":{"id":"R3Slix5llc9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from typing import Tuple\n","\n","def resize_and_pad(image: np.ndarray, mask: np.ndarray, target_size: int = 512) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Resizes an image and its corresponding mask to have the longer side equal to `target_size` and pads them to make them\n","    both have the same size. The resulting image and mask have dimensions (target_size, target_size).\n","\n","    Args:\n","        image: A numpy array representing the image to resize and pad.\n","        mask: A numpy array representing the mask to resize and pad.\n","        target_size: An integer specifying the desired size of the longer side after resizing.\n","\n","    Returns:\n","        A tuple containing two numpy arrays - the resized and padded image and the resized and padded mask.\n","    \"\"\"\n","    height, width, _ = image.shape\n","    max_dim = max(height, width)\n","    scale = target_size / max_dim\n","    new_height = int(height * scale)\n","    new_width = int(width * scale)\n","    image_resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n","    mask_resized = cv2.resize(mask, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n","    pad_height = target_size - new_height\n","    pad_width = target_size - new_width\n","    top_pad = pad_height // 2\n","    bottom_pad = pad_height - top_pad\n","    left_pad = pad_width // 2\n","    right_pad = pad_width - left_pad\n","    image_padded = np.pad(image_resized, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)), mode='constant')\n","    mask_padded = np.pad(mask_resized, ((top_pad, bottom_pad), (left_pad, right_pad)), mode='constant')\n","    return image_padded, mask_padded, (top_pad, bottom_pad, left_pad, right_pad)\n","\n","def recover_size(image_padded: np.ndarray, mask_padded: np.ndarray, orig_size: Tuple[int, int],\n","                 padding_factors: Tuple[int, int, int, int]) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Resizes a padded and resized image and mask to the original size.\n","\n","    Args:\n","        image_padded: A numpy array representing the padded and resized image.\n","        mask_padded: A numpy array representing the padded and resized mask.\n","        orig_size: A tuple containing two integers - the original height and width of the image before resizing and padding.\n","\n","    Returns:\n","        A tuple containing two numpy arrays - the recovered image and the recovered mask with dimensions `orig_size`.\n","    \"\"\"\n","    h,w,c = image_padded.shape\n","    top_pad, bottom_pad, left_pad, right_pad = padding_factors\n","    image = image_padded[top_pad:h-bottom_pad, left_pad:w-right_pad, :]\n","    mask = mask_padded[top_pad:h-bottom_pad, left_pad:w-right_pad]\n","    image_resized = cv2.resize(image, orig_size[::-1], interpolation=cv2.INTER_LINEAR)\n","    mask_resized = cv2.resize(mask, orig_size[::-1], interpolation=cv2.INTER_LINEAR)\n","    return image_resized, mask_resized\n","\n","\n","\n","\n","# if __name__ == '__main__':\n","\n","#     # image = cv2.imread('example/boat.jpg')\n","#     # mask = cv2.imread('example/boat_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","#     # image = cv2.imread('example/groceries.jpg')\n","#     # mask = cv2.imread('example/groceries_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","#     # image = cv2.imread('example/bridge.jpg')\n","#     # mask = cv2.imread('example/bridge_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","#     # image = cv2.imread('example/person_umbrella.jpg')\n","#     # mask = cv2.imread('example/person_umbrella_mask_2.png', cv2.IMREAD_GRAYSCALE)\n","#     # image = cv2.imread('example/hippopotamus.jpg')\n","#     # mask = cv2.imread('example/hippopotamus_mask_1.png', cv2.IMREAD_GRAYSCALE)\n","#     image = cv2.imread('/data1/yutao/projects/IAM/Inpaint-Anything/example/fill-anything/sample5.jpeg')\n","#     mask = cv2.imread('/data1/yutao/projects/IAM/Inpaint-Anything/example/fill-anything/sample5/mask.png', cv2.IMREAD_GRAYSCALE)\n","#     print(image.shape)\n","#     print(mask.shape)\n","#     cv2.imwrite('original_image.jpg', image)\n","#     cv2.imwrite('original_mask.jpg', mask)\n","#     image_padded, mask_padded, padding_factors = resize_and_pad(image, mask)\n","#     cv2.imwrite('padded_image.png', image_padded)\n","#     cv2.imwrite('padded_mask.png', mask_padded)\n","#     print(image_padded.shape, mask_padded.shape, padding_factors)\n","\n","#     # ^ ------------------------------------------------------------------------------------\n","#     # ^ Please conduct inpainting or filling here on the cropped image with the cropped mask\n","#     # ^ ------------------------------------------------------------------------------------\n","\n","#     # resize and pad the image and mask\n","\n","#     # perform some operation on the 512x512 image and mask\n","#     # ...\n","\n","#     # recover the image and mask to the original size\n","#     height, width, _ = image.shape\n","#     image_resized, mask_resized = recover_size(image_padded, mask_padded, (height, width), padding_factors)\n","\n","#     # save the resized and recovered image and mask\n","#     cv2.imwrite('resized_and_padded_image.png', image_padded)\n","#     cv2.imwrite('resized_and_padded_mask.png', mask_padded)\n","#     cv2.imwrite('recovered_image.png', image_resized)\n","#     cv2.imwrite('recovered_mask.png', mask_resized)\n","# Load the image and mask\n","image = cv2.imread('/content/input.png')\n","mask = cv2.imread('/content/mask_non_resized.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Resize and pad the image and mask\n","image_padded, mask_padded, padding_factors = resize_and_pad(image, mask)\n","\n","# Perform your task here\n","\n","# Recover the image and mask to the original size\n","image_recovered, mask_recovered = recover_size(image_padded, mask_padded, image.shape[:2], padding_factors)\n","\n","# Save the recovered image and mask\n","cv2.imwrite('image_recovered.jpg', image_recovered)\n","cv2.imwrite('mask_recovered.jpg', mask_recovered)"],"metadata":{"id":"_iKyk-B-v9s_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696154177909,"user_tz":-420,"elapsed":340,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"8cf17503-4bda-41a3-ce5b-c81ed18f5bfc"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from PIL import Image\n","from typing import Any, Dict, List\n","\n","\n","def load_img_to_array(img_p):\n","    img = Image.open(img_p)\n","    if img.mode == \"RGBA\":\n","        img = img.convert(\"RGB\")\n","    return np.array(img)\n","\n","\n","def save_array_to_img(img_arr, img_p):\n","    Image.fromarray(img_arr.astype(np.uint8)).save(img_p)\n","\n","\n","def dilate_mask(mask, dilate_factor=15):\n","    mask = mask.astype(np.uint8)\n","    mask = cv2.dilate(\n","        mask,\n","        np.ones((dilate_factor, dilate_factor), np.uint8),\n","        iterations=1\n","    )\n","    return mask\n","\n","def erode_mask(mask, dilate_factor=15):\n","    mask = mask.astype(np.uint8)\n","    mask = cv2.erode(\n","        mask,\n","        np.ones((dilate_factor, dilate_factor), np.uint8),\n","        iterations=1\n","    )\n","    return mask\n","\n","def show_mask(ax, mask: np.ndarray, random_color=False):\n","    mask = mask.astype(np.uint8)\n","    if np.max(mask) == 255:\n","        mask = mask / 255\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask_img = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    ax.imshow(mask_img)\n","\n","\n","def show_points(ax, coords: List[List[float]], labels: List[int], size=375):\n","    coords = np.array(coords)\n","    labels = np.array(labels)\n","    color_table = {0: 'red', 1: 'green'}\n","    for label_value, color in color_table.items():\n","        points = coords[labels == label_value]\n","        ax.scatter(points[:, 0], points[:, 1], color=color, marker='*',\n","                   s=size, edgecolor='white', linewidth=1.25)\n","\n","def get_clicked_point(img_path):\n","    img = cv2.imread(img_path)\n","    cv2.namedWindow(\"image\")\n","    cv2.imshow(\"image\", img)\n","\n","    last_point = []\n","    keep_looping = True\n","\n","    def mouse_callback(event, x, y, flags, param):\n","        nonlocal last_point, keep_looping, img\n","\n","        if event == cv2.EVENT_LBUTTONDOWN:\n","            if last_point:\n","                cv2.circle(img, tuple(last_point), 5, (0, 0, 0), -1)\n","            last_point = [x, y]\n","            cv2.circle(img, tuple(last_point), 5, (0, 0, 255), -1)\n","            cv2.imshow(\"image\", img)\n","        elif event == cv2.EVENT_RBUTTONDOWN:\n","            keep_looping = False\n","\n","    cv2.setMouseCallback(\"image\", mouse_callback)\n","\n","    while keep_looping:\n","        cv2.waitKey(1)\n","\n","    cv2.destroyAllWindows()\n","\n","    return last_point"],"metadata":{"id":"Ke9Tw19CwXv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import glob\n","import argparse\n","import torch\n","import numpy as np\n","import PIL.Image as Image\n","from pathlib import Path\n","from diffusers import StableDiffusionInpaintPipeline\n","\n","\n","def fill_img_with_sd(\n","        img: np.ndarray,\n","        mask: np.ndarray,\n","        text_prompt: str,\n","        device=\"cuda\"\n","):\n","    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n","        \"stabilityai/stable-diffusion-2-inpainting\",\n","        torch_dtype=torch.float32,\n","    ).to(device)\n","    img_crop, mask_crop = crop_for_filling_pre(img, mask)\n","    img_crop_filled = pipe(\n","        prompt=text_prompt,\n","        image=Image.fromarray(img_crop),\n","        mask_image=Image.fromarray(mask_crop)\n","    ).images[0]\n","    img_filled = crop_for_filling_post(img, mask, np.array(img_crop_filled))\n","    return img_filled\n","\n","\n","def replace_img_with_sd(\n","        img: np.ndarray,\n","        mask: np.ndarray,\n","        text_prompt: str,\n","        step: int = 50,\n","        device=\"cuda\"\n","):\n","    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n","        \"stabilityai/stable-diffusion-2-inpainting\",\n","        torch_dtype=torch.float32,\n","    ).to(device)\n","    img_padded, mask_padded, padding_factors = resize_and_pad(img, mask)\n","    img_padded = pipe(\n","        prompt=text_prompt,\n","        image=Image.fromarray(img_padded),\n","        mask_image=Image.fromarray(255 - mask_padded),\n","        num_inference_steps=step,\n","    ).images[0]\n","    height, width, _ = img.shape\n","    img_resized, mask_resized = recover_size(\n","        np.array(img_padded), mask_padded, (height, width), padding_factors)\n","    mask_resized = np.expand_dims(mask_resized, -1) / 255\n","    img_resized = img_resized * (1-mask_resized) + img * mask_resized\n","    return img_resized\n","\n","\n","def setup_args(parser):\n","    parser.add_argument(\n","        \"--input_img\", type=str, required=True,\n","        help=\"Path to a single input img\",\n","    )\n","    parser.add_argument(\n","        \"--text_prompt\", type=str, required=True,\n","        help=\"Text prompt\",\n","    )\n","    parser.add_argument(\n","        \"--input_mask_glob\", type=str, required=True,\n","        help=\"Glob to input masks\",\n","    )\n","    parser.add_argument(\n","        \"--output_dir\", type=str, required=True,\n","        help=\"Output path to the directory with results.\",\n","    )\n","    parser.add_argument(\n","        \"--seed\", type=int,\n","        help=\"Specify seed for reproducibility.\",\n","    )\n","    parser.add_argument(\n","        \"--deterministic\", action=\"store_true\",\n","        help=\"Use deterministic algorithms for reproducibility.\",\n","    )\n","\n","if __name__ == \"__main__\":\n","    \"\"\"Example usage:\n","    python lama_inpaint.py \\\n","        --input_img FA_demo/FA1_dog.png \\\n","        --input_mask_glob \"results/FA1_dog/mask*.png\" \\\n","        --text_prompt \"a teddy bear on a bench\" \\\n","        --output_dir results\n","    \"\"\"\n","    parser = argparse.ArgumentParser()\n","    setup_args(parser)\n","    args = parser.parse_args(sys.argv[1:])\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    if args.deterministic:\n","        os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","        torch.use_deterministic_algorithms(True)\n","\n","    # img_stem = Path(args.input_img).stem\n","    # mask_ps = sorted(glob.glob(args.input_mask_glob))\n","    # out_dir = Path(args.output_dir) / img_stem\n","    # out_dir.mkdir(parents=True, exist_ok=True)\n","\n","    img = load_img_to_array(\"/content/photographers-1(2).png\")\n","    mask = load_img_to_array(\"/content/photographers-1(1).png\")\n","    # for mask_p in mask_ps:\n","    #     if args.seed is not None:\n","    #         torch.manual_seed(args.seed)\n","    #     mask = load_img_to_array(mask_p)\n","    img_filled_p = out_dir / f\"filled_with_{Path(mask_p).name}\"\n","    img_filled = fill_img_with_sd(\n","        img, mask, args.text_prompt, device=device)\n","    save_array_to_img(img_filled, img_filled_p)"],"metadata":{"id":"7nICTNMTSxfQ","colab":{"base_uri":"https://localhost:8080/","height":212},"executionInfo":{"status":"error","timestamp":1696072524422,"user_tz":-420,"elapsed":1072,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"020407ff-2ee1-4c44-b569-0baa94af4157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: colab_kernel_launcher.py [-h] --input_img INPUT_IMG --text_prompt\n","                                TEXT_PROMPT --input_mask_glob INPUT_MASK_GLOB\n","                                --output_dir OUTPUT_DIR [--seed SEED]\n","                                [--deterministic]\n","colab_kernel_launcher.py: error: the following arguments are required: --input_img, --text_prompt, --input_mask_glob, --output_dir\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5_t5vzv5ghT","executionInfo":{"status":"ok","timestamp":1696074198437,"user_tz":-420,"elapsed":19085,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"991d90f7-f9ef-4d5a-dbdb-bd07fa882d45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.13.3 transformers-4.33.3\n"]}]},{"cell_type":"code","source":["!python -m pip install torch torchvision torchaudio\n","!python -m pip install -e segment_anything"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fkmRt6EO6FzH","executionInfo":{"status":"ok","timestamp":1696074395848,"user_tz":-420,"elapsed":4811,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"b7059b54-cfaa-49c4-d4c3-82694536c402"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[31mERROR: segment_anything is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install diffusers pathlib transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHaJINaF6bU5","executionInfo":{"status":"ok","timestamp":1696074432715,"user_tz":-420,"elapsed":10489,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"7ea59027-59fa-40f8-f004-4ac64af4a51b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.21.4)\n","Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.12.2)\n","Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.17.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.3.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.16.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n"]}]},{"cell_type":"code","source":["!python -m pip install torch torchvision torchaudio\n","!python -m pip install -e segment_anything\n","!python -m pip install diffusers transformers accelerate scipy safetensors"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVZNh3pz9FcS","executionInfo":{"status":"ok","timestamp":1696075157594,"user_tz":-420,"elapsed":21534,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"3dfef9a7-d0e9-44e2-bb43-dcc5e41cb2cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[31mERROR: segment_anything is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.21.4)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.3)\n","Collecting accelerate\n","  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.12.2)\n","Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.17.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.16.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.23.0\n"]}]},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","from typing import Tuple\n","import cv2\n","from PIL import Image\n","from typing import Any, Dict, List\n","import os\n","import sys\n","import glob\n","import argparse\n","import torch\n","import numpy as np\n","import PIL.Image as Image\n","from pathlib import Path\n","from diffusers import StableDiffusionInpaintPipeline\n","import transformers"],"metadata":{"id":"rd1CNJlJzJH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_for_filling_pre(image, mask, crop_size: int = 512):\n","    # Calculate the aspect ratio of the image\n","    height, width = image.shape[:2]\n","    aspect_ratio = float(width) / float(height)\n","\n","    # If the shorter side is less than 512, resize the image proportionally\n","    if min(height, width) < crop_size:\n","        if height < width:\n","            new_height = crop_size\n","            new_width = int(new_height * aspect_ratio)\n","        else:\n","            new_width = crop_size\n","            new_height = int(new_width / aspect_ratio)\n","\n","        image = cv2.resize(image, (new_width, new_height))\n","        mask = cv2.resize(mask, (new_width, new_height))\n","\n","    # Find the bounding box of the mask\n","    x, y, w, h = cv2.boundingRect(mask)\n","\n","    # Update the height and width of the resized image\n","    height, width = image.shape[:2]\n","\n","    # # If the 512x512 square cannot cover the entire mask, resize the image accordingly\n","    if w > crop_size or h > crop_size:\n","        # padding to square at first\n","        if height < width:\n","            padding = width - height\n","            image = np.pad(image, ((padding // 2, padding - padding // 2), (0, 0), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","        else:\n","            padding = height - width\n","            image = np.pad(image, ((0, 0), (padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((0, 0), (padding // 2, padding - padding // 2)), 'constant')\n","\n","        resize_factor = crop_size / max(w, h)\n","        image = cv2.resize(image, (0, 0), fx=resize_factor, fy=resize_factor)\n","        mask = cv2.resize(mask, (0, 0), fx=resize_factor, fy=resize_factor)\n","        x, y, w, h = cv2.boundingRect(mask)\n","\n","    # Calculate the crop coordinates\n","    crop_x = min(max(x + w // 2 - crop_size // 2, 0), width - crop_size)\n","    crop_y = min(max(y + h // 2 - crop_size // 2, 0), height - crop_size)\n","\n","    # Crop the image\n","    cropped_image = image[crop_y:crop_y + crop_size, crop_x:crop_x + crop_size]\n","    cropped_mask = mask[crop_y:crop_y + crop_size, crop_x:crop_x + crop_size]\n","\n","    return cropped_image, cropped_mask"],"metadata":{"id":"RmbWnUAG2q2q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_for_filling_post(\n","        image: np.array,\n","        mask: np.array,\n","        filled_image: np.array,\n","        crop_size: int = 512,\n","        ):\n","    image_copy = image.copy()\n","    mask_copy = mask.copy()\n","    # Calculate the aspect ratio of the image\n","    height, width = image.shape[:2]\n","    height_ori, width_ori = height, width\n","    aspect_ratio = float(width) / float(height)\n","\n","    # If the shorter side is less than 512, resize the image proportionally\n","    if min(height, width) < crop_size:\n","        if height < width:\n","            new_height = crop_size\n","            new_width = int(new_height * aspect_ratio)\n","        else:\n","            new_width = crop_size\n","            new_height = int(new_width / aspect_ratio)\n","\n","        image = cv2.resize(image, (new_width, new_height))\n","        mask = cv2.resize(mask, (new_width, new_height))\n","\n","    # Find the bounding box of the mask\n","    x, y, w, h = cv2.boundingRect(mask)\n","\n","    # Update the height and width of the resized image\n","    height, width = image.shape[:2]\n","\n","    # # If the 512x512 square cannot cover the entire mask, resize the image accordingly\n","    if w > crop_size or h > crop_size:\n","        flag_padding = True\n","        # padding to square at first\n","        if height < width:\n","            padding = width - height\n","            image = np.pad(image, ((padding // 2, padding - padding // 2), (0, 0), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","            padding_side = 'h'\n","        else:\n","            padding = height - width\n","            image = np.pad(image, ((0, 0), (padding // 2, padding - padding // 2), (0, 0)), 'constant')\n","            mask = np.pad(mask, ((0, 0), (padding // 2, padding - padding // 2)), 'constant')\n","            padding_side = 'w'\n","\n","        resize_factor = crop_size / max(w, h)\n","        image = cv2.resize(image, (0, 0), fx=resize_factor, fy=resize_factor)\n","        mask = cv2.resize(mask, (0, 0), fx=resize_factor, fy=resize_factor)\n","        x, y, w, h = cv2.boundingRect(mask)\n","    else:\n","        flag_padding = False\n","\n","    # Calculate the crop coordinates\n","    crop_x = min(max(x + w // 2 - crop_size // 2, 0), width - crop_size)\n","    crop_y = min(max(y + h // 2 - crop_size // 2, 0), height - crop_size)\n","\n","    # Fill the image\n","    image[crop_y:crop_y + crop_size, crop_x:crop_x + crop_size] = filled_image\n","    if flag_padding:\n","        image = cv2.resize(image, (0, 0), fx=1/resize_factor, fy=1/resize_factor)\n","        if padding_side == 'h':\n","            image = image[padding // 2:padding // 2 + height_ori, :]\n","        else:\n","            image = image[:, padding // 2:padding // 2 + width_ori]\n","\n","    image = cv2.resize(image, (width_ori, height_ori))\n","\n","    image_copy[mask_copy==255] = image[mask_copy==255]\n","    return image_copy"],"metadata":{"id":"Llp00yRM2x2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def resize_and_pad(image: np.ndarray, mask: np.ndarray, target_size: int = 512) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Resizes an image and its corresponding mask to have the longer side equal to `target_size` and pads them to make them\n","    both have the same size. The resulting image and mask have dimensions (target_size, target_size).\n","\n","    Args:\n","        image: A numpy array representing the image to resize and pad.\n","        mask: A numpy array representing the mask to resize and pad.\n","        target_size: An integer specifying the desired size of the longer side after resizing.\n","\n","    Returns:\n","        A tuple containing two numpy arrays - the resized and padded image and the resized and padded mask.\n","    \"\"\"\n","    height, width, _ = image.shape\n","    max_dim = max(height, width)\n","    scale = target_size / max_dim\n","    new_height = int(height * scale)\n","    new_width = int(width * scale)\n","    image_resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n","    mask_resized = cv2.resize(mask, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n","    pad_height = target_size - new_height\n","    pad_width = target_size - new_width\n","    top_pad = pad_height // 2\n","    bottom_pad = pad_height - top_pad\n","    left_pad = pad_width // 2\n","    right_pad = pad_width - left_pad\n","    image_padded = np.pad(image_resized, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)), mode='constant')\n","    mask_padded = np.pad(mask_resized, ((top_pad, bottom_pad), (left_pad, right_pad)), mode='constant')\n","    return image_padded, mask_padded, (top_pad, bottom_pad, left_pad, right_pad)\n","\n","def recover_size(image_padded: np.ndarray, mask_padded: np.ndarray, orig_size: Tuple[int, int],\n","                 padding_factors: Tuple[int, int, int, int]) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Resizes a padded and resized image and mask to the original size.\n","\n","    Args:\n","        image_padded: A numpy array representing the padded and resized image.\n","        mask_padded: A numpy array representing the padded and resized mask.\n","        orig_size: A tuple containing two integers - the original height and width of the image before resizing and padding.\n","\n","    Returns:\n","        A tuple containing two numpy arrays - the recovered image and the recovered mask with dimensions `orig_size`.\n","    \"\"\"\n","    h,w,c = image_padded.shape\n","    top_pad, bottom_pad, left_pad, right_pad = padding_factors\n","    image = image_padded[top_pad:h-bottom_pad, left_pad:w-right_pad, :]\n","    mask = mask_padded[top_pad:h-bottom_pad, left_pad:w-right_pad]\n","    image_resized = cv2.resize(image, orig_size[::-1], interpolation=cv2.INTER_LINEAR)\n","    mask_resized = cv2.resize(mask, orig_size[::-1], interpolation=cv2.INTER_LINEAR)\n","    return image_resized, mask_resized\n"],"metadata":{"id":"8PB99GZM27O_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_img_to_array(img_p):\n","    img = Image.open(img_p)\n","    if img.mode == \"RGBA\":\n","        img = img.convert(\"RGB\")\n","    return np.array(img)\n","\n","\n","def save_array_to_img(img_arr, img_p):\n","    Image.fromarray(img_arr.astype(np.uint8)).save(img_p)"],"metadata":{"id":"CgX2FD2v3E9I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def replace_img_with_sd(\n","        img: np.ndarray,\n","        mask: np.ndarray,\n","        text_prompt: str,\n","        step: int = 50,\n","        device=\"cuda\"\n","):\n","    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n","        \"stabilityai/stable-diffusion-2-inpainting\",\n","        torch_dtype=torch.float32,\n","    ).to(device)\n","    img_padded, mask_padded, padding_factors = resize_and_pad(img, mask)\n","    img_padded = pipe(\n","        prompt=text_prompt,\n","        image=Image.fromarray(img_padded),\n","        mask_image=Image.fromarray(255 - mask_padded),\n","        num_inference_steps=step,\n","    ).images[0]\n","    height, width, _ = img.shape\n","    img_resized, mask_resized = recover_size(\n","        np.array(img_padded), mask_padded, (height, width), padding_factors)\n","    mask_resized = np.expand_dims(mask_resized, -1) / 255\n","    img_resized = img_resized * (1-mask_resized) + img * mask_resized\n","    return img_resized"],"metadata":{"id":"MrMAIurO3Xh9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = load_img_to_array(\"/content/photographers-1(2).png\")\n","mask = load_img_to_array(\"/content/photographers-1(1).png\")\n","text_prompt = \"The warm coffee house\"\n","device = \"cuda\"\n","\n","img_background = replace_img_with_sd(img, mask, text_prompt, device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549},"id":"UFmDrwqd4AH1","executionInfo":{"status":"error","timestamp":1696076384507,"user_tz":-420,"elapsed":8,"user":{"displayName":"Dương Bách","userId":"04758487621955449563"}},"outputId":"f43f61e3-89e5-4885-f7d4-b33fa6ccc2e3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-a3718e8897e8>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg_background\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_img_with_sd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-2454f91ae3a6>\u001b[0m in \u001b[0;36mreplace_img_with_sd\u001b[0;34m(img, mask, text_prompt, step, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ):\n\u001b[0;32m----> 8\u001b[0;31m     pipe = StableDiffusionInpaintPipeline.from_pretrained(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"stabilityai/stable-diffusion-2-inpainting\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/dummy_torch_and_transformers_objects.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     if name in [\n","\u001b[0;31mImportError\u001b[0m: \nStableDiffusionInpaintPipeline requires the transformers library but it was not found in your environment. You can install it with pip: `pip\ninstall transformers`\n","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}